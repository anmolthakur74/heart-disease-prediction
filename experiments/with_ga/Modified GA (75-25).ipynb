{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6539ff4b-4fde-4259-a261-6e7b92f3db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d854338d-9e63-456a-99b3-7ba956eed9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6aaa3af-c63a-43bb-97fd-b53bdbecb3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\n",
    "    'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target'  \n",
    "]\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6129eb2-9b47-4b5c-89ec-5329eb41346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  sex  cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
      "0 -0.268437    1   0 -0.377636 -0.659332    0        1  0.821321      0   \n",
      "1 -0.158157    1   0  0.479107 -0.833861    1        0  0.255968      1   \n",
      "2  1.716595    1   0  0.764688 -1.396233    0        1 -1.048692      1   \n",
      "3  0.724079    1   0  0.936037 -0.833861    0        1  0.516900      0   \n",
      "4  0.834359    0   0  0.364875  0.930822    1        1 -1.874977      0   \n",
      "\n",
      "    oldpeak  slope  ca  thal  target  \n",
      "0 -0.060888      2   2     3       0  \n",
      "1  1.727137      0   0     3       0  \n",
      "2  1.301417      0   0     3       0  \n",
      "3 -0.912329      2   1     3       0  \n",
      "4  0.705408      1   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "numerical_features = [\n",
    "    'age', 'trestbps', 'chol', 'thalach', 'oldpeak' \n",
    "]\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80c747c-950a-4f57-a6ca-d425508b32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    526\n",
      "0    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count plot to check class distribution\n",
    "sns.countplot(x=df['target'])\n",
    "plt.title(\"Heart Disease Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Print class distribution\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab99cda-1f09-447f-94e2-1172679acc37",
   "metadata": {},
   "source": [
    "# Random Forest+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4b14b5-47c6-46fc-ad12-e4a570759889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Test Accuracy (Random Forest): 1.0\n",
      "Test Precision (Random Forest): 1.0\n",
      "Test Recall (Random Forest): 1.0\n",
      "Test AUC-ROC (Random Forest): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train Random Forest with selected features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "rf_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = rf_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Random Forest):\", test_accuracy_rf)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = rf_model.predict(X_test[:, selected_features])\n",
    "y_proba = rf_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_rf = precision_score(y_test, y_pred)\n",
    "test_recall_rf = recall_score(y_test, y_pred)\n",
    "test_auc_rf = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Random Forest):\", test_precision_rf)\n",
    "print(\"Test Recall (Random Forest):\", test_recall_rf)\n",
    "print(\"Test AUC-ROC (Random Forest):\", test_auc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02833e7-e40a-4f2e-b8e5-882519327b8a",
   "metadata": {},
   "source": [
    "# XGBoost+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842055ce-7ed9-4c69-8937-e1c10377310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (XGBoost): 0.9922178988326849\n",
      "Test Precision (XGBoost): 1.0\n",
      "Test Recall (XGBoost): 0.9848484848484849\n",
      "Test AUC-ROC (XGBoost): 0.9995151515151516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train XGBoost with selected features\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "xgb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = xgb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (XGBoost):\", test_accuracy_xgb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = xgb_model.predict(X_test[:, selected_features])\n",
    "y_proba = xgb_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_xgb = precision_score(y_test, y_pred)\n",
    "test_recall_xgb = recall_score(y_test, y_pred)\n",
    "test_auc_xgb = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (XGBoost):\", test_precision_xgb)\n",
    "print(\"Test Recall (XGBoost):\", test_recall_xgb)\n",
    "print(\"Test AUC-ROC (XGBoost):\", test_auc_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffcf51-c42e-444f-ac31-d08f3d436ed8",
   "metadata": {},
   "source": [
    "# Logistic Regression+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dc66c0-9270-4583-ba04-7b6c0616d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Test Accuracy (Logistic Regression): 0.8287937743190662\n",
      "Test Precision (Logistic Regression): 0.8142857142857143\n",
      "Test Recall (Logistic Regression): 0.8636363636363636\n",
      "Test AUC-ROC (Logistic Regression): 0.9095151515151515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train Logistic Regression with selected features\n",
    "logreg_model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "logreg_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = logreg_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_logreg = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Logistic Regression):\", test_accuracy_logreg)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = logreg_model.predict(X_test[:, selected_features])\n",
    "y_proba = logreg_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_logreg = precision_score(y_test, y_pred)\n",
    "test_recall_logreg = recall_score(y_test, y_pred)\n",
    "test_auc_logreg = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Logistic Regression):\", test_precision_logreg)\n",
    "print(\"Test Recall (Logistic Regression):\", test_recall_logreg)\n",
    "print(\"Test AUC-ROC (Logistic Regression):\", test_auc_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1649c-0400-434a-ad10-ac0bd051c131",
   "metadata": {},
   "source": [
    "# KNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a777475-6db2-4384-9841-3a0c8fe53e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Test Accuracy (KNN): 0.8521400778210116\n",
      "Test Precision (KNN): 0.873015873015873\n",
      "Test Recall (KNN): 0.8333333333333334\n",
      "Test AUC-ROC (KNN): 0.9519090909090909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)  # Using KNN\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train KNN with selected features\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "knn_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = knn_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (KNN):\", test_accuracy_knn)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "y_proba = knn_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (KNN):\", precision)\n",
    "print(\"Test Recall (KNN):\", recall)\n",
    "print(\"Test AUC-ROC (KNN):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a77425-657e-4a78-842e-c134cf4959e3",
   "metadata": {},
   "source": [
    "# SVM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4516affd-1337-4722-a7c5-75905a04e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (SVM): 0.8365758754863813\n",
      "Test Precision (SVM): 0.7960526315789473\n",
      "Test Recall (SVM): 0.9166666666666666\n",
      "Test AUC-ROC (SVM): 0.8980606060606061\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = SVC(kernel='linear', random_state=random_seed)  # Using SVM\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train SVM with selected features\n",
    "svm_model = SVC(kernel='linear', random_state=random_seed)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "svm_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = svm_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (SVM):\", test_accuracy_svm)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# SVM does not support predict_proba by default, so use decision_function + normalization\n",
    "decision_scores = svm_model.decision_function(X_test[:, selected_features])\n",
    "# Normalize decision function to [0,1] for AUC-ROC\n",
    "normalized_scores = (decision_scores - decision_scores.min()) / (decision_scores.max() - decision_scores.min())\n",
    "auc_roc = roc_auc_score(y_test, normalized_scores)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (SVM):\", precision)\n",
    "print(\"Test Recall (SVM):\", recall)\n",
    "print(\"Test AUC-ROC (SVM):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a564e7b-4a6b-4406-8e4f-279f88d543a9",
   "metadata": {},
   "source": [
    "# Decision Tree+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7de5d5b-dea3-44dd-9b18-fe7d63a990ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 0 1 1 0 1 0 0 1 0]\n",
      "Test Accuracy (Decision Tree): 1.0\n",
      "Test Precision (Decision Tree): 1.0\n",
      "Test Recall (Decision Tree): 1.0\n",
      "Test AUC-ROC (Decision Tree): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = DecisionTreeClassifier(random_state=random_seed)  # Using Decision Tree\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train Decision Tree with selected features\n",
    "dt_model = DecisionTreeClassifier(random_state=random_seed)\n",
    "dt_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = dt_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_dt = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Decision Tree):\", test_accuracy_dt)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# For AUC-ROC, use predict_proba if available\n",
    "if hasattr(dt_model, \"predict_proba\"):\n",
    "    y_proba = dt_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_proba)\n",
    "else:\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)  # Fallback in case predict_proba is not supported\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Decision Tree):\", precision)\n",
    "print(\"Test Recall (Decision Tree):\", recall)\n",
    "print(\"Test AUC-ROC (Decision Tree):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cff9b4-f952-4b22-9c9c-8bf9ca090812",
   "metadata": {},
   "source": [
    "# Naive Bayes+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e020fc4-eed5-4e40-b214-8eab7ee5d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Test Accuracy (Nave Bayes): 0.8404669260700389\n",
      "Test Precision (Nave Bayes): 0.8273381294964028\n",
      "Test Recall (Nave Bayes): 0.8712121212121212\n",
      "Test AUC-ROC (Nave Bayes): 0.9074545454545455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = GaussianNB()  # Using Nave Bayes\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train Nave Bayes with selected features\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = nb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Nave Bayes):\", test_accuracy_nb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = nb_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Nave Bayes):\", precision)\n",
    "print(\"Test Recall (Nave Bayes):\", recall)\n",
    "print(\"Test AUC-ROC (Nave Bayes):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db997bed-ef28-4ef7-9bb4-17b407ad7028",
   "metadata": {},
   "source": [
    "# LightGBM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f7df97-a6a5-4c8b-9b7b-d6b794d00b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (LightGBM): 1.0\n",
      "Test Precision (LightGBM): 1.0\n",
      "Test Recall (LightGBM): 1.0\n",
      "Test AUC-ROC (LightGBM): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=random_seed, verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train LightGBM with selected features\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=random_seed)\n",
    "lgb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = lgb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_lgb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (LightGBM):\", test_accuracy_lgb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = lgb_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (LightGBM):\", precision)\n",
    "print(\"Test Recall (LightGBM):\", recall)\n",
    "print(\"Test AUC-ROC (LightGBM):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4182f-57eb-43ec-856e-a74d3782a3bd",
   "metadata": {},
   "source": [
    "# CNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ebffb3-8f6a-416a-9f67-b055d0452df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5364 - loss: 0.6924   \n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7353 - loss: 0.5949 \n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8008 - loss: 0.5023 \n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.8095 - loss: 0.4529\n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7927 - loss: 0.4196 \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (CNN with 75-25 split): 0.7782101167315175\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step\n",
      "Test Precision (CNN): 0.7659574468085106\n",
      "Test Recall (CNN): 0.8181818181818182\n",
      "Test AUC-ROC (CNN): 0.8936969696969698\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)  # Fewer splits for speed\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Build Final CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN Model (Reduced Epochs for Speed)\n",
    "cnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (cnn_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_cnn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (CNN with 75-25 split):\", test_accuracy_cnn)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = cnn_model.predict(X_test)  # Get probabilities from CNN\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (CNN):\", precision)\n",
    "print(\"Test Recall (CNN):\", recall)\n",
    "print(\"Test AUC-ROC (CNN):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e5b77-358a-4769-ad52-7c0d47e7e23e",
   "metadata": {},
   "source": [
    "# LSTM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b37d6fb-2dda-4c63-9348-8b95907bd4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5600 - loss: 0.6893\n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 0.6327\n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.5687\n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.5640\n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.5364 \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (LSTM with 75-25 split): 0.77431906614786\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Precision (LSTM): 0.7846153846153846\n",
      "Test Recall (LSTM): 0.7727272727272727\n",
      "Test AUC-ROC (LSTM): 0.8444242424242424\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Reshape input for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build Final LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train LSTM Model (Reduced Epochs for Speed)\n",
    "lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_lstm = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (LSTM with 75-25 split):\", test_accuracy_lstm)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = lstm_model.predict(X_test)  # Get probabilities from LSTM\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (LSTM):\", precision)\n",
    "print(\"Test Recall (LSTM):\", recall)\n",
    "print(\"Test AUC-ROC (LSTM):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8efa3-c4c9-45c8-8c1e-4dfe89069bbe",
   "metadata": {},
   "source": [
    "# MLP+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe529100-0f81-48d1-9499-976576be78b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6272 - loss: 0.6521   \n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.4893 \n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4130 \n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8442 - loss: 0.3755 \n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3757 \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (MLP with 75-25 split): 0.8560311284046692\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Precision: 0.8321678321678322\n",
      "Recall: 0.9015151515151515\n",
      "AUC-ROC: 0.8547575757575758\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Build Final MLP Model\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train MLP Model (Reduced Epochs for Speed)\n",
    "mlp_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (mlp_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (MLP with 75-25 split):\", test_accuracy_mlp)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = (mlp_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
