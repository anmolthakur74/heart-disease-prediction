{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533281ba-4fb8-409b-b61b-e82044166254",
   "metadata": {},
   "source": [
    "# Random Forest+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910b34e5-fadc-48c9-a001-376f60614de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Mean Test Accuracy (Random Forest with K-Fold CV): 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_rf = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy_scores_rf.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (Random Forest with K-Fold CV):\", np.mean(accuracy_scores_rf))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))  # AUC-ROC for probability\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f569f-ca7c-4913-b61e-ed3b37891fb1",
   "metadata": {},
   "source": [
    "# XGBoost+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249dbe64-8ed3-4680-a20a-c5c7158b5ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Mean Test Accuracy (XGBoost with K-Fold CV): 0.9902439024390244\n",
      "Mean Precision: 0.996116504854369\n",
      "Mean Recall: 0.9847619047619048\n",
      "Mean AUC-ROC: 0.9996571428571428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_xgb = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracy_scores_xgb.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (XGBoost with K-Fold CV):\", np.mean(accuracy_scores_xgb))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for XGBoost\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_pred_prob = xgb_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439330d-6978-43a2-badc-33adacf0da68",
   "metadata": {},
   "source": [
    "# Logistic Regression+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9bb77c-47f4-4a3e-b7c8-cfd3abedef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Mean Test Accuracy (Logistic Regression with K-Fold CV): 0.8458536585365855\n",
      "Mean Precision: 0.8354640591476686\n",
      "Mean Recall: 0.872524707996406\n",
      "Mean AUC-ROC: 0.9069237605162133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_lr = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    lr_model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    accuracy_scores_lr.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (Logistic Regression with K-Fold CV):\", np.mean(accuracy_scores_lr))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for Logistic Regression\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    lr_model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    y_pred_prob = lr_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e1afc-2d8b-44b7-b945-98f4692447f3",
   "metadata": {},
   "source": [
    "# KNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469e0471-dd1e-482b-8251-2056d609ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Mean Test Accuracy (KNN with K-Fold CV): 0.862439024390244\n",
      "Mean Precision: 0.8998890105878058\n",
      "Mean Recall: 0.8231805929919138\n",
      "Mean AUC-ROC: 0.964367034223638\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)  # KNN with k=5\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_knn = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)  # KNN with k=5\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    accuracy_scores_knn.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (KNN with K-Fold CV):\", np.mean(accuracy_scores_knn))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for KNN\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)  # KNN with k=5\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    y_pred_prob = knn_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b8a26-b772-4d12-8dcb-29e88b6e533f",
   "metadata": {},
   "source": [
    "# SVM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f306c94-de3b-408e-a5ca-f4bfe439a64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Mean Test Accuracy (SVM with K-Fold CV): 0.8917073170731709\n",
      "Mean Precision: 0.8755508010519263\n",
      "Mean Recall: 0.9201437556154538\n",
      "Mean AUC-ROC: 0.9474428163031936\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = SVC(kernel='rbf', C=1.0, random_state=RANDOM_SEED)  # SVM with RBF kernel\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_svm = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, random_state=RANDOM_SEED)  # SVM with RBF kernel\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy_scores_svm.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (SVM with K-Fold CV):\", np.mean(accuracy_scores_svm))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for SVM\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, random_state=RANDOM_SEED, probability=True)  # Enable probability estimates\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_pred_prob = svm_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7035b-536a-4ce1-b9a3-c451951bab69",
   "metadata": {},
   "source": [
    "# Decision Tree+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0939c7-09c2-4fe1-b82e-d084fbeaeee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 0 1 1 0 1 0 0 1 0]\n",
      "Mean Test Accuracy (Decision Tree with K-Fold CV): 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_dt = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    accuracy_scores_dt.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (Decision Tree with K-Fold CV):\", np.mean(accuracy_scores_dt))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for Decision Tree\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    y_pred_prob = dt_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dd4c2-01bc-4511-9630-38ffeb352ebe",
   "metadata": {},
   "source": [
    "# Naive Bayes+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268462bd-7bd8-4726-9d7d-a46865c6e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Mean Test Accuracy (Naive Bayes with K-Fold CV): 0.8487804878048781\n",
      "Mean Precision: 0.8337847081393388\n",
      "Mean Recall: 0.8821024258760108\n",
      "Mean AUC-ROC: 0.9039907430096109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = GaussianNB()  # Naive Bayes Classifier\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_nb = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    accuracy_scores_nb.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (Naive Bayes with K-Fold CV):\", np.mean(accuracy_scores_nb))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for Naive Bayes\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    y_pred_prob = nb_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7569c6-8365-472a-8c5d-547685f88da9",
   "metadata": {},
   "source": [
    "# LightGBM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42815dec-fd32-49fb-91c9-e1659985ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Mean Test Accuracy (LightGBM with K-Fold CV): 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=RANDOM_SEED, verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "accuracy_scores_lgb = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=RANDOM_SEED,verbose=-1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    accuracy_scores_lgb.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Mean Test Accuracy (LightGBM with K-Fold CV):\", np.mean(accuracy_scores_lgb))\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Initialize lists for the new metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation on the selected features for LightGBM\n",
    "for train_idx, test_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_test = X[train_idx][:, selected_features], X[test_idx][:, selected_features]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=RANDOM_SEED, verbose=-1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    y_pred_prob = lgb_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))  # AUC-ROC based on predicted probabilities\n",
    "\n",
    "# Output Results\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ac5e-ce32-4798-9320-bd462079d550",
   "metadata": {},
   "source": [
    "# CNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6778a97-755b-45f0-8133-b4d6762dbf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5425 - loss: 0.7075   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.5894 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.5048 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4580 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.4229 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5628 - loss: 0.6868   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7228 - loss: 0.5779 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.5086 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8090 - loss: 0.4419 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8129 - loss: 0.4157 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6175 - loss: 0.6374   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7912 - loss: 0.5249 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.4726 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8136 - loss: 0.4292 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 0.4158 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5192 - loss: 0.6944   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.5712 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8106 - loss: 0.4865 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7972 - loss: 0.4296 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8108 - loss: 0.4063 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 0.6782 \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7518 - loss: 0.5598 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4695 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.4177 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.4037 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Mean Accuracy: 0.8195121951219513\n",
      "Mean Precision: 0.798703382216334\n",
      "Mean Recall: 0.8706558849955076\n",
      "Mean AUC-ROC: 0.9044831277736938\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)  # Using K-Fold CV\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Initialize lists for metrics\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Stratified K-Fold Cross-Validation for CNN\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "for train_idx, val_idx in skf.split(X[:, selected_features], y):\n",
    "    X_train, X_val = X[train_idx][:, selected_features], X[val_idx][:, selected_features]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Build Final CNN Model\n",
    "    cnn_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train CNN Model (Reduced Epochs for Speed)\n",
    "    cnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "    # Test the Model\n",
    "    y_pred = (cnn_model.predict(X_val) > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_scores.append(accuracy_score(y_val, y_pred))\n",
    "    precision_scores.append(precision_score(y_val, y_pred))\n",
    "    recall_scores.append(recall_score(y_val, y_pred))\n",
    "\n",
    "    # For AUC-ROC, use the probabilities predicted by the sigmoid activation\n",
    "    y_pred_prob = cnn_model.predict(X_val)[:, 0]  # Use the first column for probability\n",
    "    roc_auc_scores.append(roc_auc_score(y_val, y_pred_prob))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Mean Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe2e35-7460-4053-ac46-5cfcc4ed313f",
   "metadata": {},
   "source": [
    "# LSTM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8715c302-851b-437d-8e9a-23b33a1b57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 0.6915\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.6359\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5786\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.5491\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5256\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5556 - loss: 0.6775\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.6300\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7475 - loss: 0.5446\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.5251\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.5196\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.6687\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.5966\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.5329\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.5230\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7551 - loss: 0.5144\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.6855\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.6429\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7162 - loss: 0.5627\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.5430\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.5274\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 0.6840\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.6279\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5417\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7560 - loss: 0.5356\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.5006\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Mean Accuracy: 0.7892682926829269\n",
      "Mean Precision: 0.7575591397849462\n",
      "Mean Recall: 0.8688409703504043\n",
      "Mean AUC-ROC: 0.8377486890468022\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "X_selected = X[:, selected_features]\n",
    "\n",
    "# Initialize lists for metrics\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Stratified K-Fold Cross-Validation for LSTM\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "for train_idx, test_idx in skf.split(X_selected, y):\n",
    "    X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Reshape input for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build LSTM Model\n",
    "    lstm_model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train LSTM Model (Reduced Epochs for Speed)\n",
    "    lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "    # Test the Model\n",
    "    y_pred = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "    # For AUC-ROC, use the probabilities predicted by the sigmoid activation\n",
    "    y_pred_prob = lstm_model.predict(X_test)[:, 0]  # Use the first column for probability\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Mean Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Mean Precision:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall:\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC:\", np.mean(roc_auc_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d682c8cc-54ed-4492-809d-950ed7454f18",
   "metadata": {},
   "source": [
    "# MLP+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44fc97f2-7765-4c0e-aa0e-c98b8c0af899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Mean Test Accuracy (MLP with Stratified K-Fold CV): 0.8556097560975611\n",
      "Mean Precision (MLP with Stratified K-Fold CV): 0.8273047820395586\n",
      "Mean Recall (MLP with Stratified K-Fold CV): 0.9125067385444743\n",
      "Mean AUC-ROC (MLP with Stratified K-Fold CV): 0.9213609845081543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "X_selected = X[:, selected_features]\n",
    "\n",
    "# Initialize lists for metrics\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold Cross-Validation with MLP\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "for train_idx, val_idx in skf.split(X_selected, y):\n",
    "    X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Build MLP Model\n",
    "    mlp_model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train MLP Model (Reduced Epochs for Speed)\n",
    "    mlp_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
    "\n",
    "    # Validate the Model\n",
    "    y_pred = (mlp_model.predict(X_val) > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy_scores.append(accuracy_score(y_val, y_pred))\n",
    "    precision_scores.append(precision_score(y_val, y_pred))\n",
    "    recall_scores.append(recall_score(y_val, y_pred))\n",
    "\n",
    "    # For AUC-ROC, use the probabilities predicted by the sigmoid activation\n",
    "    y_pred_prob = mlp_model.predict(X_val)[:, 0]  # Use the first column for probability\n",
    "    roc_auc_scores.append(roc_auc_score(y_val, y_pred_prob))\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Mean Test Accuracy (MLP with Stratified K-Fold CV):\", np.mean(accuracy_scores))\n",
    "print(\"Mean Precision (MLP with Stratified K-Fold CV):\", np.mean(precision_scores))\n",
    "print(\"Mean Recall (MLP with Stratified K-Fold CV):\", np.mean(recall_scores))\n",
    "print(\"Mean AUC-ROC (MLP with Stratified K-Fold CV):\", np.mean(roc_auc_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
