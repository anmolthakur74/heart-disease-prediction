{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e82da193-3982-4b3f-876e-3bf40ef96371",
   "metadata": {},
   "source": [
    "# Random Forest+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179775e1-dd85-4ecc-b37a-56f218a72508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Test Accuracy (Random Forest): 1.0\n",
      "Test Precision (Random Forest): 1.0\n",
      "Test Recall (Random Forest): 1.0\n",
      "Test AUC-ROC (Random Forest): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train Random Forest with selected features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "rf_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = rf_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Random Forest):\", test_accuracy_rf)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = rf_model.predict(X_test[:, selected_features])\n",
    "y_proba = rf_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_rf = precision_score(y_test, y_pred)\n",
    "test_recall_rf = recall_score(y_test, y_pred)\n",
    "test_auc_rf = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Random Forest):\", test_precision_rf)\n",
    "print(\"Test Recall (Random Forest):\", test_recall_rf)\n",
    "print(\"Test AUC-ROC (Random Forest):\", test_auc_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7490de-db76-46b6-8b3d-7d3ae6bebd98",
   "metadata": {},
   "source": [
    "# XGBoost+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a8c30c-38dd-4e44-80b8-95a73f675817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (XGBoost): 0.9902439024390244\n",
      "Test Precision (XGBoost): 0.9813084112149533\n",
      "Test Recall (XGBoost): 1.0\n",
      "Test AUC-ROC (XGBoost): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train XGBoost with selected features\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100, max_depth=3, min_child_weight=3, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "xgb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = xgb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (XGBoost):\", test_accuracy_xgb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = xgb_model.predict(X_test[:, selected_features])\n",
    "y_proba = xgb_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_xgb = precision_score(y_test, y_pred)\n",
    "test_recall_xgb = recall_score(y_test, y_pred)\n",
    "test_auc_xgb = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (XGBoost):\", test_precision_xgb)\n",
    "print(\"Test Recall (XGBoost):\", test_recall_xgb)\n",
    "print(\"Test AUC-ROC (XGBoost):\", test_auc_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384c19b-9b74-4daa-96e8-9f24f4798796",
   "metadata": {},
   "source": [
    "# Logistic Regression+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c799895-d3e4-47c5-87eb-5210fbead838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Test Accuracy (Logistic Regression): 0.8536585365853658\n",
      "Test Precision (Logistic Regression): 0.8205128205128205\n",
      "Test Recall (Logistic Regression): 0.9142857142857143\n",
      "Test AUC-ROC (Logistic Regression): 0.9152380952380952\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train Logistic Regression with selected features\n",
    "logreg_model = LogisticRegression(max_iter=500, random_state=RANDOM_SEED)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "logreg_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = logreg_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_logreg = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Logistic Regression):\", test_accuracy_logreg)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test the Model\n",
    "y_pred = logreg_model.predict(X_test[:, selected_features])\n",
    "y_proba = logreg_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "\n",
    "# Evaluation Metrics\n",
    "test_precision_logreg = precision_score(y_test, y_pred)\n",
    "test_recall_logreg = recall_score(y_test, y_pred)\n",
    "test_auc_logreg = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Logistic Regression):\", test_precision_logreg)\n",
    "print(\"Test Recall (Logistic Regression):\", test_recall_logreg)\n",
    "print(\"Test AUC-ROC (Logistic Regression):\", test_auc_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811c4a2-984d-43cf-a21a-c3985f1ef59d",
   "metadata": {},
   "source": [
    "# KNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d833b5-c24a-4c1e-9df5-c9925cdf185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 0 1 0 1 0 0 1 1 0 1 1]\n",
      "Test Accuracy (KNN): 0.8731707317073171\n",
      "Test Precision (KNN): 0.8761904761904762\n",
      "Test Recall (KNN): 0.8761904761904762\n",
      "Test AUC-ROC (KNN): 0.9644761904761905\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)  # Using KNN\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def modified_genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = modified_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Train KNN with selected features\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "knn_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = knn_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (KNN):\", test_accuracy_knn)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "y_proba = knn_model.predict_proba(X_test[:, selected_features])[:, 1]  # For AUC-ROC\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (KNN):\", precision)\n",
    "print(\"Test Recall (KNN):\", recall)\n",
    "print(\"Test AUC-ROC (KNN):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17bca1b-c111-40bb-98f3-0325528462c5",
   "metadata": {},
   "source": [
    "# SVM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47307b7e-d321-4869-a450-1b67b83ba6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (SVM): 0.8341463414634146\n",
      "Test Precision (SVM): 0.7795275590551181\n",
      "Test Recall (SVM): 0.9428571428571428\n",
      "Test AUC-ROC (SVM): 0.9102857142857143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = SVC(kernel='linear', random_state=random_seed)  # Using SVM\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Modified Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Modified Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train SVM with selected features\n",
    "svm_model = SVC(kernel='linear', random_state=random_seed)\n",
    "\n",
    "# Train the model (NO EARLY STOPPING)\n",
    "svm_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = svm_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (SVM):\", test_accuracy_svm)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# SVM does not support predict_proba by default, so use decision_function + normalization\n",
    "decision_scores = svm_model.decision_function(X_test[:, selected_features])\n",
    "# Normalize decision function to [0,1] for AUC-ROC\n",
    "normalized_scores = (decision_scores - decision_scores.min()) / (decision_scores.max() - decision_scores.min())\n",
    "auc_roc = roc_auc_score(y_test, normalized_scores)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (SVM):\", precision)\n",
    "print(\"Test Recall (SVM):\", recall)\n",
    "print(\"Test AUC-ROC (SVM):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b63aad-2e31-44d1-8524-198f8ccadff7",
   "metadata": {},
   "source": [
    "# Decision Tree+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d559c92-9037-4242-96ed-46b76064c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 0 1 1 0 1 0 0 1 0]\n",
      "Test Accuracy (Decision Tree): 1.0\n",
      "Test Precision (Decision Tree): 1.0\n",
      "Test Recall (Decision Tree): 1.0\n",
      "Test AUC-ROC (Decision Tree): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = DecisionTreeClassifier(random_state=random_seed)  # Using Decision Tree\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train Decision Tree with selected features\n",
    "dt_model = DecisionTreeClassifier(random_state=random_seed)\n",
    "dt_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = dt_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_dt = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Decision Tree):\", test_accuracy_dt)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# For AUC-ROC, use predict_proba if available\n",
    "if hasattr(dt_model, \"predict_proba\"):\n",
    "    y_proba = dt_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_proba)\n",
    "else:\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)  # Fallback in case predict_proba is not supported\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Decision Tree):\", precision)\n",
    "print(\"Test Recall (Decision Tree):\", recall)\n",
    "print(\"Test AUC-ROC (Decision Tree):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9609683-0f8f-4450-8306-a3310b71a1f4",
   "metadata": {},
   "source": [
    "# Naive Bayes+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938704ed-6b86-47c9-b83c-57655ca834ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "Test Accuracy (Naïve Bayes): 0.8341463414634146\n",
      "Test Precision (Naïve Bayes): 0.8034188034188035\n",
      "Test Recall (Naïve Bayes): 0.8952380952380953\n",
      "Test AUC-ROC (Naïve Bayes): 0.9137142857142858\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = GaussianNB()  # Using Naïve Bayes\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train Naïve Bayes with selected features\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = nb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (Naïve Bayes):\", test_accuracy_nb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = nb_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (Naïve Bayes):\", precision)\n",
    "print(\"Test Recall (Naïve Bayes):\", recall)\n",
    "print(\"Test AUC-ROC (Naïve Bayes):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9707fa-4d3f-4c3a-b006-b85d7e01aa57",
   "metadata": {},
   "source": [
    "# LightGBM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bae46f-6006-41a7-8395-50bd8e200d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Selection: [1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      "Test Accuracy (LightGBM): 1.0\n",
      "Test Precision (LightGBM): 1.0\n",
      "Test Recall (LightGBM): 1.0\n",
      "Test AUC-ROC (LightGBM): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['target']).values  # Feature matrix\n",
    "y = df['target'].values  # Target variable\n",
    "\n",
    "# Fitness function using Stratified K-Fold Cross-Validation\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]  # Select features based on chromosome\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=random_seed, verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)  # Return average accuracy\n",
    "\n",
    "# Genetic Algorithm for Feature Selection\n",
    "def genetic_algorithm(X, y, num_generations=50, population_size=20, mutation_rate=0.1):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.01:  # Convergence check\n",
    "            break\n",
    "\n",
    "        parents = population[:4]  # Select top 4 parents\n",
    "        offspring = np.mean(parents, axis=0) > 0.5  # Crossover strategy\n",
    "        offspring = np.array(offspring, dtype=int)  # Convert boolean to int\n",
    "\n",
    "        # Mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "best_chromosome = genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "# Train LightGBM with selected features\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=random_seed, verbose=-1)\n",
    "lgb_model.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = lgb_model.predict(X_test[:, selected_features])\n",
    "test_accuracy_lgb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Test Accuracy (LightGBM):\", test_accuracy_lgb)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = lgb_model.predict_proba(X_test[:, selected_features])[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (LightGBM):\", precision)\n",
    "print(\"Test Recall (LightGBM):\", recall)\n",
    "print(\"Test AUC-ROC (LightGBM):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231549c-3b75-42d9-bab3-60111889fd0d",
   "metadata": {},
   "source": [
    "# MLP+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09858977-f7bb-4918-895f-86b85eb475ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6688 - loss: 0.6337   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.4591 \n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.4063 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8580 - loss: 0.3657 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3607 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (MLP with 70-30 split): 0.8195121951219512\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Precision: 0.7698412698412699\n",
      "Recall: 0.9238095238095239\n",
      "AUC-ROC: 0.8169047619047619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Build Final MLP Model\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train MLP Model (Reduced Epochs for Speed)\n",
    "mlp_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (mlp_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (MLP with 70-30 split):\", test_accuracy_mlp)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = (mlp_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37563b1e-114b-4101-b429-a004c48f0d86",
   "metadata": {},
   "source": [
    "# CNN+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0132a618-54ce-46cf-a462-fbae17bf383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.7049   \n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7583 - loss: 0.5833\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.4845 \n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8080 - loss: 0.4387 \n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4254 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (CNN with 80-20 split): 0.775609756097561\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test Precision (CNN): 0.7521367521367521\n",
      "Test Recall (CNN): 0.8380952380952381\n",
      "Test AUC-ROC (CNN): 0.8846666666666668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)  # Fewer splits for speed\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Build Final CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN Model (Reduced Epochs for Speed)\n",
    "cnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (cnn_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_cnn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (CNN with 80-20 split):\", test_accuracy_cnn)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = cnn_model.predict(X_test)  # Get probabilities from CNN\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (CNN):\", precision)\n",
    "print(\"Test Recall (CNN):\", recall)\n",
    "print(\"Test AUC-ROC (CNN):\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169e16e-9152-4dec-a413-12939c36d4fb",
   "metadata": {},
   "source": [
    "# LSTM+Modified GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e8772c-4895-427e-b82a-9ba1448c1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5497 - loss: 0.6893\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6961 - loss: 0.6193\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5441\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7651 - loss: 0.5260\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5181\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Best Feature Selection: [1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Selected Feature Count: 9\n",
      "Test Accuracy (LSTM with 80-20 split): 0.775609756097561\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Precision (LSTM): 0.736\n",
      "Test Recall (LSTM): 0.8761904761904762\n",
      "Test AUC-ROC (LSTM): 0.8353333333333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "# Enable warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Set fixed random seed for full reproducibility\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure TensorFlow operates deterministically\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'target']\n",
    "le = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['target']).values.astype(np.float32)\n",
    "y = df['target'].values.astype(np.int32)\n",
    "\n",
    "# Fitness function using Stratified K-Fold CV with Logistic Regression\n",
    "def fitness_function(chromosome, X, y):\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid empty feature sets\n",
    "\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_selected, y):\n",
    "        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Logistic Regression for fast evaluation\n",
    "        model = LogisticRegression(max_iter=100, solver='liblinear', random_state=RANDOM_SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_scores.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "\n",
    "    return np.mean(accuracy_scores)\n",
    "\n",
    "# Optimized Genetic Algorithm for Faster Feature Selection\n",
    "def fast_genetic_algorithm(X, y, num_generations=20, population_size=10, mutation_rate=0.05):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(2, size=(population_size, num_features))\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness_scores = np.array([fitness_function(chrom, X, y) for chrom in population])\n",
    "        sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        population = population[sorted_indices]\n",
    "\n",
    "        # Early stopping if fitness doesn't improve significantly\n",
    "        if fitness_scores[0] - fitness_scores[-1] <= 0.005:\n",
    "            break\n",
    "\n",
    "        # Select top 2 parents\n",
    "        parents = population[:2]\n",
    "\n",
    "        # Create new offspring using uniform crossover\n",
    "        offspring = (parents[0] + parents[1]) // 2\n",
    "        offspring = np.array(offspring, dtype=int)\n",
    "\n",
    "        # Apply mutation\n",
    "        mutation_mask = np.random.rand(*offspring.shape) < mutation_rate\n",
    "        offspring[mutation_mask] = 1 - offspring[mutation_mask]\n",
    "\n",
    "        if fitness_function(offspring, X, y) > fitness_scores[-1]:\n",
    "            population[-1] = offspring  # Replace worst individual\n",
    "\n",
    "    return population[0]  # Return best chromosome\n",
    "\n",
    "# Run Optimized GA for Feature Selection\n",
    "best_chromosome = fast_genetic_algorithm(X, y)\n",
    "selected_features = np.where(best_chromosome == 1)[0]\n",
    "\n",
    "# Train/Test Split (70-30) using the best-selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, selected_features], y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Reshape input for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build Final LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train LSTM Model (Reduced Epochs for Speed)\n",
    "lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "y_pred = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy_lstm = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output Results\n",
    "print(\"Best Feature Selection:\", best_chromosome)\n",
    "print(\"Selected Feature Count:\", len(selected_features))\n",
    "print(\"Test Accuracy (LSTM with 80-20 split):\", test_accuracy_lstm)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Evaluation Metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# AUC-ROC using predicted probabilities\n",
    "y_proba = lstm_model.predict(X_test)  # Get probabilities from LSTM\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Output Results\n",
    "print(\"Test Precision (LSTM):\", precision)\n",
    "print(\"Test Recall (LSTM):\", recall)\n",
    "print(\"Test AUC-ROC (LSTM):\", auc_roc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
